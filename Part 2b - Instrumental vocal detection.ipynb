{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental vs. Vocal Detection in Music with Deep Learning\n",
    "\n",
    "This tutorial shows how different Convolutional Neural Network architectures are used for the detecting whether a piece of music is instrumental or contains vocals.\n",
    "\n",
    "\n",
    "The data set used is the [MagnaTagATune Dataset](http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset), but a smaller subset of it, with only 1 sample excerpt of each of the original audio files.\n",
    "\n",
    "It consists of 5405 files, each 30 seconds long. \n",
    "\n",
    "The annotations for this contain a multitude of tags, include some that hint at whether the file is instrumental or vocal. (see [Create 2 classes from a list of tags](#Create-2-classes-from-a-list-of-tags) below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Python 3.5\n",
    "* Keras >= 2.1.1\n",
    "* Tensorflow\n",
    "* scikit-learn >= 0.18\n",
    "* Pandas\n",
    "* Librosa\n",
    "* MatplotLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "This tutorial contains:\n",
    "* Loading and Preprocessing of Audio files\n",
    "* Loading class files from CSV and using Label Encoder\n",
    "* Audio Preprocessing: Generating log Mel spectrograms\n",
    "* Standardization of Data\n",
    "* Convolutional Neural Networks\n",
    "* Train/Test set split\n",
    "* ...\n",
    "\n",
    "You can execute the following code blocks by pressing SHIFT+Enter consecutively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "The (subsampled) data set can be downloaded from [here](https://owncloud.tuwien.ac.at/index.php/s/c2VEkev4YvLgUYu).\n",
    "\n",
    "Please unzip it.\n",
    "\n",
    "Set the path to the unpacked folder in the next box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = '/home/tlidy/data/MagnaTagATune'\n",
    "AUDIO_PATH = os.path.join(DATA_PATH, 'audio')\n",
    "META_PATH = os.path.join(DATA_PATH, 'metadata')\n",
    "NPZ_FILE = '/home/tlidy/data/mel_spectrogram_segments_96x1366.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd # Pandas for reading CSV files and easier Data handling in preparation\n",
    "\n",
    "# Deep Learning\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports for audio reading and processing\n",
    "import audio_spectrogram as rp\n",
    "from audiofile_read import audiofile_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Metadata\n",
    "\n",
    "The tab-separated file contains pairs of filename TAB class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>no voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>...</th>\n",
       "      <th>female singer</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp3_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3</th>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3</th>\n",
       "      <td>6021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3</th>\n",
       "      <td>11847</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3</th>\n",
       "      <td>17119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3</th>\n",
       "      <td>25118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-06-cyead-378-407.mp3</th>\n",
       "      <td>26533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-07-telekonology-117-146.mp3</th>\n",
       "      <td>33637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0/american_bach_soloists-j_s__bach__cantatas_volume_v-01-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_i_sinfonia-117-146.mp3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0/american_bach_soloists-j_s__bach__cantatas_volume_v-02-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_ii_recitative__gleichwie_der_regen_und_schnee-30-59.mp3</th>\n",
       "      <td>5864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0/american_bach_soloists-j_s__bach__cantatas_volume_v-03-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_iii_recitative_and_litany__mein_gott_hier_wird_mein_herze_sein-88-117.mp3</th>\n",
       "      <td>11264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    clip_id  no voice  singer  \\\n",
       "mp3_path                                                                        \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     1119         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     6021         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    11847         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    17119         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    25118         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    26533         0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    33637         0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...       29         0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...     5864         0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...    11264         0       0   \n",
       "\n",
       "                                                    duet  plucking  hard rock  \\\n",
       "mp3_path                                                                        \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...     0         0          0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...     0         0          0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...     0         0          0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...     0         0          0   \n",
       "\n",
       "                                                    world  bongos  \\\n",
       "mp3_path                                                            \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...      0       0   \n",
       "\n",
       "                                                    harpsichord  \\\n",
       "mp3_path                                                          \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...            0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...            0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...            0   \n",
       "\n",
       "                                                    female singing   ...     \\\n",
       "mp3_path                                                             ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0   ...      \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...               0   ...      \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...               0   ...      \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...               0   ...      \n",
       "\n",
       "                                                    female singer  rap  metal  \\\n",
       "mp3_path                                                                        \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0    0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...              0    0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...              0    0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...              0    0      0   \n",
       "\n",
       "                                                    hip hop  quick  water  \\\n",
       "mp3_path                                                                    \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0      0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0      0   \n",
       "\n",
       "                                                    baroque  women  fiddle  \\\n",
       "mp3_path                                                                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0       0   \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0      0       0   \n",
       "\n",
       "                                                    english  \n",
       "mp3_path                                                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...        0  \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0  \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0  \n",
       "0/american_bach_soloists-j_s__bach__cantatas_vo...        0  \n",
       "\n",
       "[10 rows x 189 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = os.path.join(META_PATH,'annotations_final_subsample.csv')\n",
    "\n",
    "# we select the last column (-1) as the index column (= filename)\n",
    "metadata = pd.read_csv(csv_file, index_col=0, sep='\\t')\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>clasical</th>\n",
       "      <th>...</th>\n",
       "      <th>female singer</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp3_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    no voice  singer  duet  \\\n",
       "mp3_path                                                                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0       0     0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0       0     0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0       0     0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0       0     0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0       0     0   \n",
       "\n",
       "                                                    plucking  hard rock  \\\n",
       "mp3_path                                                                  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0          0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...         0          0   \n",
       "\n",
       "                                                    world  bongos  \\\n",
       "mp3_path                                                            \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0   \n",
       "\n",
       "                                                    harpsichord  \\\n",
       "mp3_path                                                          \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...            0   \n",
       "\n",
       "                                                    female singing  clasical  \\\n",
       "mp3_path                                                                       \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0         0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0         0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0         0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0         0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...               0         0   \n",
       "\n",
       "                                                     ...     female singer  \\\n",
       "mp3_path                                             ...                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...   ...                 0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...   ...                 0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...   ...                 0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...   ...                 0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...   ...                 0   \n",
       "\n",
       "                                                    rap  metal  hip hop  \\\n",
       "mp3_path                                                                  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...    0      0        0   \n",
       "\n",
       "                                                    quick  water  baroque  \\\n",
       "mp3_path                                                                    \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0        0   \n",
       "\n",
       "                                                    women  fiddle  english  \n",
       "mp3_path                                                                    \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0        0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0       0        0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the uneeded colum\"clip_id\"\n",
    "cols = \"clip_id\"\n",
    "metadata.drop(cols,axis=1,inplace=True)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 classes from a list of tags\n",
    "\n",
    "There are plenty of \"tags\" in this data set which hint at wether a track is \"vocal\" or \"instrumental\". We group these tags and finally come up with 1 boolean column saying whether a track is \"vocal\" or \"instrumental\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vocal = ['singer', 'female singing', 'female opera', 'male vocal', 'vocals', 'men', 'female', 'female voice', 'voice', 'male voice', 'girl', 'chanting', 'talking', 'choral', 'male singer', 'man singing', 'male opera', 'chant', 'man', 'female vocal', 'male vocals', 'vocal', 'woman', 'woman singing', 'singing', 'female vocals', 'voices', 'choir', 'female singer', 'women', 'choir', 'women']\n",
    "\n",
    "tags_instrumental = ['instrumental', 'no voice', 'no voices', 'no vocals', 'no vocal', 'no singing', 'no singer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singer</th>\n",
       "      <th>female singing</th>\n",
       "      <th>female opera</th>\n",
       "      <th>male vocal</th>\n",
       "      <th>vocals</th>\n",
       "      <th>men</th>\n",
       "      <th>female</th>\n",
       "      <th>female voice</th>\n",
       "      <th>voice</th>\n",
       "      <th>male voice</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>woman singing</th>\n",
       "      <th>singing</th>\n",
       "      <th>female vocals</th>\n",
       "      <th>voices</th>\n",
       "      <th>choir</th>\n",
       "      <th>female singer</th>\n",
       "      <th>women</th>\n",
       "      <th>choir</th>\n",
       "      <th>women</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp3_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    singer  female singing  \\\n",
       "mp3_path                                                                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0               0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0               0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0               0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0               0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0               0   \n",
       "\n",
       "                                                    female opera  male vocal  \\\n",
       "mp3_path                                                                       \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0           0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0           0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0           0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0           0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0           0   \n",
       "\n",
       "                                                    vocals  men  female  \\\n",
       "mp3_path                                                                  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0    0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0    0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0    0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0    0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...       0    0       0   \n",
       "\n",
       "                                                    female voice  voice  \\\n",
       "mp3_path                                                                  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0      0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...             0      0   \n",
       "\n",
       "                                                    male voice  ...    woman  \\\n",
       "mp3_path                                                        ...            \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...           0  ...        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...           0  ...        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...           0  ...        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...           0  ...        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...           0  ...        0   \n",
       "\n",
       "                                                    woman singing  singing  \\\n",
       "mp3_path                                                                     \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0        0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0        0   \n",
       "\n",
       "                                                    female vocals  voices  \\\n",
       "mp3_path                                                                    \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0       0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...              0       0   \n",
       "\n",
       "                                                    choir  female singer  \\\n",
       "mp3_path                                                                   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0              0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0              0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0              0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0              0   \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0              0   \n",
       "\n",
       "                                                    women  choir  women  \n",
       "mp3_path                                                                 \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0      0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0      0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0      0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0      0  \n",
       "d/ambient_teknology-the_all_seeing_eye_project-...      0      0      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[tags_vocal].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mp3_path\n",
       "d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3           False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3    False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3             False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3     False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set vocal to True of any of the tags_vocal are 1\n",
    "gt_vocal = metadata[tags_vocal].any(axis=1)\n",
    "gt_vocal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mp3_path\n",
       "d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3           False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3    False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3             False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3     False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set instrumental to True of any of the tags_instrumental are 1\n",
    "gt_instrumental = metadata[tags_instrumental].any(axis=1)\n",
    "gt_instrumental.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We can only use the tag if EITHER instrumental OR vocal is True.</b><br>\n",
    "If both of them are True or both of them are False, we cannot trust the groundtruth data. Ergo we have to remove these and retain only the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mp3_path\n",
       "d/ambient_teknology-the_all_seeing_eye_project-01-cyclops-262-291.mp3           False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-02-all_seeing_eye-175-204.mp3    False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-03-black-175-204.mp3             False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-04-confusion_says-88-117.mp3     False\n",
       "d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retain = np.logical_xor(gt_vocal,gt_instrumental)\n",
    "retain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('From originally', 3023, 'input examples, we can only retain', 959, 'trusted ones in our groundtruth')\n"
     ]
    }
   ],
   "source": [
    "n_orig = len(gt_vocal)\n",
    "\n",
    "n_retain = sum(retain)\n",
    "\n",
    "print(\"From originally\", n_orig, \"input examples, we can only retain\",n_retain, \"trusted ones in our groundtruth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end we cut from gt_vocal only the exampls to retain. If they are True they are vocal, if they are False, they are instrumental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mp3_path\n",
       "d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3                                                                                                                   False\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-03-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_iii_recitative_and_litany__mein_gott_hier_wird_mein_herze_sein-88-117.mp3     True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-07-weinen_klagen_sorgen_zagen_bwv_12_ii_chorus__weinen_klagen_sorgen_zagen-262-291.mp3                                                  True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-08-weinen_klagen_sorgen_zagen_bwv_12_iii_recitative__wir_mussen_durch_viel_truebsal-0-29.mp3                                            True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-09-weinen_klagen_sorgen_zagen_bwv_12_iv_aria__kreuz_und_krone_sind_verbunden-59-88.mp3                                                  True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-11-weinen_klagen_sorgen_zagen_bwv_12_vi_aria__sei_getreu-88-117.mp3                                                                     True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-13-nun_komm_der_heiden_heiland_bwv_61_i_ouverture__nun_komm_der_heiden_heiland-59-88.mp3                                                True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-14-nun_komm_der_heiden_heiland_bwv_61_ii_recitative__der_heiland_ist_gekommen-30-59.mp3                                                 True\n",
       "0/american_bach_soloists-j_s__bach__cantatas_volume_v-15-nun_komm_der_heiden_heiland_bwv_61_iii_aria__komm_jesu_komm_zu_deiner_kirche-117-146.mp3                                             True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_final = gt_vocal[retain]\n",
    "gt_final.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 vocal tracks\n"
     ]
    }
   ],
   "source": [
    "print(str(sum(gt_final)) + \" vocal tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 instrumental tracks\n"
     ]
    }
   ],
   "source": [
    "print(str(sum(np.logical_not(gt_final))) + \" instrumental tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create two lists: one with filenames and one with associated classes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index in list of strings\n",
    "filelist = gt_final.index.tolist()\n",
    "# convert boolean to int and store in other list\n",
    "classes = (gt_final * 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d/ambient_teknology-the_all_seeing_eye_project-05-the_beholder-291-320.mp3',\n",
       " '0/american_bach_soloists-j_s__bach__cantatas_volume_v-03-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_iii_recitative_and_litany__mein_gott_hier_wird_mein_herze_sein-88-117.mp3',\n",
       " '0/american_bach_soloists-j_s__bach__cantatas_volume_v-07-weinen_klagen_sorgen_zagen_bwv_12_ii_chorus__weinen_klagen_sorgen_zagen-262-291.mp3',\n",
       " '0/american_bach_soloists-j_s__bach__cantatas_volume_v-08-weinen_klagen_sorgen_zagen_bwv_12_iii_recitative__wir_mussen_durch_viel_truebsal-0-29.mp3',\n",
       " '0/american_bach_soloists-j_s__bach__cantatas_volume_v-09-weinen_klagen_sorgen_zagen_bwv_12_iv_aria__kreuz_und_krone_sind_verbunden-59-88.mp3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted to Numpy array as needed by Keras\n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) directly from the original MP3 files\n",
    "\n",
    "alternatively see shortcut to load feature file below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-4dc652e2215c>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-4dc652e2215c>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    print(\".\", end='')\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list_spectrograms = [] # spectrograms are put into a list first\n",
    "\n",
    "# desired output parameters\n",
    "\n",
    "# orig\n",
    "#n_mel_bands = 40   # y axis\n",
    "#frames = 80        # x axis\n",
    "\n",
    "# enhanced\n",
    "n_mel_bands = 96   # y axis\n",
    "#frames = 1366        # x axis\n",
    "frames = 683        # x axis\n",
    "\n",
    "\n",
    "# some FFT parameters\n",
    "fft_window_size=512\n",
    "fft_overlap = 0.5\n",
    "hop_size = int(fft_window_size*(1-fft_overlap))\n",
    "segment_size = fft_window_size + (frames-1) * hop_size # segment size for desired # frames\n",
    "\n",
    "for filename in filelist:\n",
    "    print(\".\", end='')\n",
    "    filepath = os.path.join(AUDIO_PATH, filename)\n",
    "    samplerate, samplewidth, wavedata = audiofile_read(filepath,verbose=False)\n",
    "    sample_length = wavedata.shape[0]\n",
    "\n",
    "    # make Mono (in case of multiple channels / stereo)\n",
    "    if wavedata.ndim > 1:\n",
    "        wavedata = np.mean(wavedata, 1)\n",
    "        \n",
    "    # take only a segment; choose start position:\n",
    "    #pos = 0 # beginning\n",
    "    pos = int(wavedata.shape[0]/2 - segment_size/2) # center minus half segment size\n",
    "    wav_segment = wavedata[pos:pos+segment_size]\n",
    "\n",
    "    # 1) FFT spectrogram \n",
    "    spectrogram = rp.calc_spectrogram(wav_segment,fft_window_size,fft_overlap)\n",
    "\n",
    "    # 2) Transform to perceptual Mel scale (uses librosa.filters.mel)\n",
    "    spectrogram = rp.transform2mel(spectrogram,samplerate,fft_window_size,n_mel_bands)\n",
    "        \n",
    "    # 3) Log 10 transform\n",
    "    spectrogram = np.log10(spectrogram)\n",
    "    \n",
    "    list_spectrograms.append(spectrogram)\n",
    "        \n",
    "print(\"\\nRead\", len(filelist), \"audio files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, samplewidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"An audio segment is\", round(float(segment_size) / samplerate, 2), \"seconds long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) load pre-extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(NPZ_FILE) as npz:\n",
    "    data = npz[\"data\"]\n",
    "    filelist = npz[\"filenames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3023, 96, 55)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Waveform and Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can skip this if you do not have matplotlib installed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# show 1 sec wave segment\n",
    "plt.plot(wav_segment)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show spectrogram\n",
    "fig = plt.imshow(spectrogram, origin='lower', aspect='auto')\n",
    "fig.set_cmap('jet')\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 1 big array of list of spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the input data to the right data type used by Keras Deep Learning (GPU)\n",
    "dtype = keras.backend.floatx()\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of many spectrograms is made into 1 big array with 3 dimensions\n",
    "data = np.array(list_spectrograms, dtype=dtype)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Inf values\n",
    "\n",
    "As in our preprocessing some files generated an Inf value in the log10 computation, we replace those by 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.isinf(data)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "<b>Always standardize</b> the data before feeding it into the Neural Network!\n",
    "\n",
    "We use <b>Zero-mean Unit-variance standardization</b> (also known as Z-score normalization).\n",
    "Here, we use <b>attribute-wise standardization</b>, i.e. each pixel is standardized individually, as opposed to computing a single mean and single standard deviation of all values.\n",
    "\n",
    "('Flat' standardization would also be possible, but we have seen benefits of attribut-wise standardization in our experiments).\n",
    "\n",
    "We use the StandardScaler from the scikit-learn package for our purpose.\n",
    "As it works typically on vector data, we have to vectorize (i.e. reshape) our matrices first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "N, ydim, xdim = data.shape\n",
    "data = data.reshape(N, xdim*ydim)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean and standard deviation: two vectors with same length as data.shape[1]\n",
    "scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "A Convolutional Neural Network (ConvNet or CNN) is a type of (deep) Neural Network that is well-suited for 2D axes data, such as images or spectrograms, as it is optimized for learning from spatial proximity. Its core elements are 2D filter kernels which essentially learn the weights of the Neural Network, and downscaling functions such as Max Pooling.\n",
    "\n",
    "A CNN can have one or more Convolution layers, each of them having an arbitrary number of N filters (which define the depth of the CNN layer), following typically by a pooling step, which aggregates neighboring pixels together and thus reduces the image resolution by retaining only the maximum values of neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "### Adding the channel\n",
    "\n",
    "As CNNs were initially made for image data, we need to add a dimension for the color channel to the data. RGB images typically have a 3rd dimension with the color. \n",
    "\n",
    "<b>Spectrograms, however, are considered like greyscale images, as in the previous tutorial.\n",
    "Likewise we need to add an extra dimension for compatibility with the CNN implementation.</b>\n",
    "\n",
    "For greyscale images, we add the number 1 as the depth of the additional dimension of the input shape (for RGB color images, the number of channels is 3).\n",
    "\n",
    "<i>Note on Tensorflow vs. Theano:</i>\n",
    "\n",
    "In Theano, traditionally the color channel was the <b>first</b> dimension in the image shape. \n",
    "In Tensorflow, the color channel is the <b>last</b> dimension in the image shape. \n",
    "\n",
    "This can be configured in ~/.keras/keras.json: \"image_dim_ordering\": \"th\" or \"tf\" (for Theano or Tensorflow) *or* with \"image_data_format\" set to \"channels_first\" or \"channels_last\".\n",
    "\n",
    "Tensorflow is now the default image ordering for Kears (\"tf\" and/or \"channels_last\").\n",
    "To be on the safe side, we added the if statement below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1 # for grey-scale, 3 for RGB, but usually already present in the data\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_last':  # TENSORFLOW\n",
    "    # Tensorflow ordering (~/.keras/keras.json: \"image_dim_ordering\": \"tf\")\n",
    "    data = data.reshape(data.shape[0], ydim, xdim, n_channels)\n",
    "else: # THEANO\n",
    "    # Theano ordering (~/.keras/keras.json: \"image_dim_ordering\": \"th\")\n",
    "    data = data.reshape(data.shape[0], n_channels, ydim, xdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store the new shape of the images in the 'input_shape' variable.\n",
    "# take all dimensions except the 0th one (which is the number of images)\n",
    "input_shape = data.shape[1:]  \n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test Set Split\n",
    "\n",
    "We split the original full data set into two parts: Train Set (75%) and Test Set (25%).\n",
    "\n",
    "Note: \n",
    "For demo purposes we use only 1 split here. A better way to do it is to use **Cross-Validation**, doing the split multiple times, iterating training and testing over the splits and averaging the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_size = 0.25 # % portion of whole data set to keep for testing, i.e. 75% is used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN INDEX: [1522  737  992 ...  515 1107 1526]\n",
      "TEST INDEX: [  23 1200  453 1502  958 1371  919  886  192  720  857  466  362 1270\n",
      " 1254  765  351  142  458  271  123  457  226  717  377  621  152 1247\n",
      "  522 1091  975 1521  845  374 1496  303 1230  861  868  635  547 1493\n",
      "  654 1219 1443  991    7 1133  348 1423 1110  878  371 1136 1583  860\n",
      " 1175   85 1299  604 1301 1027  103 1049 1500 1260 1169 1353 1227 1075\n",
      "  832  205  558 1235  676 1529 1563  586  332 1393  921 1464 1207 1516\n",
      "  887  207  370  406  535  569  319  724 1494 1131 1143   29  651  507\n",
      "  870  684  822  437  560  320 1318  564  508  627  864 1297  477  859\n",
      " 1525  954  324  249  472 1220 1623  129 1139  294 1010  204 1228 1021\n",
      " 1549    3 1277 1122  552   54  298  282 1387  258  528 1566  666 1140\n",
      "  259 1152 1186 1590 1615  118  336   41 1008  183 1183  610  943  229\n",
      " 1043 1355 1015 1046 1330  148   31  951  672  964 1144 1368  726  977\n",
      " 1415   49  990 1585  581 1452  662  956 1172  426 1333  875  596 1456\n",
      "  161 1093  432  995  927   76 1450 1407   75 1004 1092  190 1572  254\n",
      "  139 1184 1620  885  511 1127  773  593  929 1595  462  892  871  969\n",
      "  594 1577  540 1416 1231  939  742  113  567  410 1447  648  577  625\n",
      " 1012  542  451   24 1376  484   72 1118  889 1508 1397 1253  330  687\n",
      "  789 1223  779 1040  197  430  640  965  455  411  970  833  823  198\n",
      "  926  960  199 1086 1283 1051  185  474 1459  310 1202  274  602  615\n",
      " 1424 1028 1524 1286  578 1019 1003  853  464  658  584  232   52 1064\n",
      " 1571  438 1221  116 1285  240  346  907  759   45  112 1360  529 1603\n",
      "  275  496 1367  891  603 1300  616 1364  847 1374  189 1173 1155  749\n",
      "  308  436  922  354 1552 1298  106   90 1159  579 1441 1402  386  725\n",
      "  844  973 1089  283 1232  788  399 1124 1158 1007 1414 1208  407  598\n",
      "  441   14  571 1523  460 1176 1431 1471  821 1054 1454 1408  322 1495\n",
      " 1340 1279  242 1545  846 1059  384  166  383 1457  224  253 1445  280\n",
      "    6  289  959  245  503  634  914  270  194  531  630 1181  792  119\n",
      " 1428  378 1592  855  748  397  805 1347  711   78  394  950 1455 1198\n",
      " 1558   67  130  538 1218  834  132  895 1078    0  373 1561   35 1384\n",
      "  931]\n"
     ]
    }
   ],
   "source": [
    "# Stratified Split retains the class balance in both sets\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0)\n",
    "splits = splitter.split(data, classes)\n",
    "\n",
    "for train_index, test_index in splits:\n",
    "    print(\"TRAIN INDEX:\", train_index)\n",
    "    print(\"TEST INDEX:\", test_index)\n",
    "    train_set = data[train_index]\n",
    "    test_set = data[test_index]\n",
    "    train_classes = classes[train_index]\n",
    "    test_classes = classes[test_index]\n",
    "# Note: this for loop is only executed once if n_splits==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1218, 96, 1366, 1)\n",
      "(407, 96, 1366, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: Class 0: 329 Class 1: 889\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts: Class 0:\", sum(train_classes==0), \"Class 1:\", sum(train_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CNN Models in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKIP - Creating a Single Layer and a Two Layer CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try: (comment/uncomment code in the following code block)\n",
    "* 1 Layer\n",
    "* 2 Layer\n",
    "* more conv_filters\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0) # make results repeatable\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#conv_filters = 16   # number of convolution filters (= CNN depth)\n",
    "conv_filters = 32   # number of convolution filters (= CNN depth)\n",
    "\n",
    "# Layer 1\n",
    "model.add(Convolution2D(conv_filters, (3, 3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "# Layer 2\n",
    "model.add(Convolution2D(conv_filters, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "# After Convolution, we have a 16*x*y matrix output\n",
    "# In order to feed this to a Full(Dense) layer, we need to flatten all data\n",
    "# Note: Keras does automatic shape inference, i.e. it knows how many (flat) input units the next layer will need,\n",
    "# so no parameter is needed for the Flatten() layer.\n",
    "model.add(Flatten()) \n",
    "\n",
    "# Full layer\n",
    "model.add(Dense(256, activation='sigmoid')) \n",
    "\n",
    "# Output layer\n",
    "# For binary/2-class problems use ONE sigmoid unit, \n",
    "# for multi-class/multi-label problems use n output units and activation='softmax!'\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get OverflowError: Range exceeds valid bounds in the above box, check the correct Theano vs. Tensorflow ordering in the box before and your keras.json configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 94, 1364, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 682, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 47, 682, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 680, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 340, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 239360)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               61276416  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 61,286,241\n",
      "Trainable params: 61,286,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function \n",
    "loss = 'binary_crossentropy'  # 'categorical_crossentropy' for multi-class problems\n",
    "\n",
    "# Optimizer = Stochastic Gradient Descent\n",
    "optimizer = 'sgd' \n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING the model\n",
    "epochs = 15\n",
    "history = model.fit(train_set, train_classes, batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy goes up pretty quickly for 1 layer on Train set! Also on Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# always execute this, and then a box of accuracy_score below to print the result\n",
    "test_pred = model.predict_classes(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 layer\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 layer\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 layer + 32 convolution filters\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 layer + 32 convolution filters + Dropout\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact CNN\n",
    "\n",
    "This is a 5 layer Convolutional Neural Network inspired and adapted from Keunwoo Choi (https://github.com/keunwoochoi/music-auto_tagging-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports for more fancy stuff\n",
    "\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompactCNN(input_shape, nb_conv, nb_filters, n_mels, normalize, nb_hidden, dense_units, \n",
    "               output_shape, activation, dropout, multiple_segments=False, graph_model=False, input_tensor=None):\n",
    "    \n",
    "    melgram_input = Input(shape=input_shape)\n",
    "\n",
    "    if n_mels >= 256:\n",
    "        poolings = [(2, 4), (4, 4), (4, 5), (2, 4), (4, 4)]\n",
    "    elif n_mels >= 128:\n",
    "        poolings = [(2, 4), (4, 4), (2, 5), (2, 4), (4, 4)]\n",
    "    elif n_mels >= 96:\n",
    "        poolings = [(2, 4), (3, 4), (2, 5), (2, 4), (4, 4)]\n",
    "    elif n_mels >= 72:\n",
    "        poolings = [(2, 4), (3, 4), (2, 5), (2, 4), (3, 4)]\n",
    "    elif n_mels >= 64:\n",
    "        poolings = [(2, 4), (2, 4), (2, 5), (2, 4), (4, 4)]\n",
    "\n",
    "    # Determine input axis\n",
    "    if keras.backend.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "        freq_axis = 2\n",
    "        time_axis = 3\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        freq_axis = 1\n",
    "        time_axis = 2\n",
    "            \n",
    "    # Input block\n",
    "    #x = BatchNormalization(axis=time_axis, name='bn_0_freq')(melgram_input)\n",
    "        \n",
    "    if normalize == 'batch':\n",
    "        x = BatchNormalization(axis=freq_axis, name='bn_0_freq')(melgram_input)\n",
    "    elif normalize in ('data_sample', 'time', 'freq', 'channel'):\n",
    "        x = Normalization2D(normalize, name='nomalization')(melgram_input)\n",
    "    elif normalize in ('no', 'False'):\n",
    "        x = melgram_input\n",
    "\n",
    "    # Conv block 1\n",
    "    x = Convolution2D(nb_filters[0], (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='bn1')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=poolings[0], name='pool1')(x)\n",
    "        \n",
    "    # Conv block 2\n",
    "    x = Convolution2D(nb_filters[1], (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='bn2')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=poolings[1], name='pool2')(x)\n",
    "        \n",
    "    # Conv block 3\n",
    "    x = Convolution2D(nb_filters[2], (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='bn3')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=poolings[2], name='pool3')(x)\n",
    "    \n",
    "    # Conv block 4\n",
    "    if nb_conv > 3:        \n",
    "        x = Convolution2D(nb_filters[3], (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization(axis=channel_axis, name='bn4')(x)\n",
    "        x = ELU()(x)   \n",
    "        x = MaxPooling2D(pool_size=poolings[3], name='pool4')(x)\n",
    "        \n",
    "    # Conv block 5\n",
    "    if nb_conv == 5:\n",
    "        x = Convolution2D(nb_filters[4], (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization(axis=channel_axis, name='bn5')(x)\n",
    "        x = ELU()(x)\n",
    "        x = MaxPooling2D(pool_size=poolings[4], name='pool5')(x)\n",
    "\n",
    "    # Flatten the outout of the last Conv Layer\n",
    "    x = Flatten()(x)\n",
    "      \n",
    "    if nb_hidden == 1:\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(dense_units, activation='relu')(x)\n",
    "    elif nb_hidden == 2:\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(dense_units[0], activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(dense_units[1], activation='relu')(x) \n",
    "    else:\n",
    "        raise ValueError(\"More than 2 hidden units not supported at the moment.\")\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(output_shape, activation=activation, name = 'output')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(melgram_input, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Convolutional Layers\n",
    "nb_conv_layers = 5\n",
    "\n",
    "# number of Filters in each layer\n",
    "nb_filters = [64,64,64,128,128]\n",
    "\n",
    "# number of hidden layers at the end of the model\n",
    "nb_hidden = 1 # 2\n",
    "\n",
    "# how many neurons in each hidden layer\n",
    "dense_units = 128 #[128,56]\n",
    "\n",
    "# which activation function to use for OUTPUT\n",
    "activation = 'sigmoid'\n",
    "\n",
    "# which type of normalization\n",
    "normalization = 'batch'\n",
    "\n",
    "# droupout\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompactCNN(input_shape, nb_conv = nb_conv_layers, nb_filters= nb_filters, n_mels = 96, \n",
    "                           normalize=normalization, \n",
    "                           nb_hidden = nb_hidden, dense_units = dense_units, \n",
    "                           output_shape = 1, activation = activation, \n",
    "                           dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 1366, 1)       0         \n",
      "_________________________________________________________________\n",
      "bn_0_freq (BatchNormalizatio (None, 96, 1366, 1)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 96, 1366, 64)      640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 96, 1366, 64)      256       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 96, 1366, 64)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 341, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 341, 64)       36928     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 48, 341, 64)       256       \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 48, 341, 64)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 16, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 85, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 16, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 16, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 8, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 17, 128)        73856     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 8, 17, 128)        512       \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 8, 17, 128)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 314,753\n",
      "Trainable params: 313,665\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = 'binary_crossentropy' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "sgd = optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.01)#lr=0.001 decay = 0.03\n",
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# We use mostly ADAM\n",
    "adam = optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.01)\n",
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-07, schedule_decay=0.004)\n",
    "\n",
    "# choose\n",
    "optimizer = adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "metrics = ['accuracy', precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other\n",
    "batch_size = 32 \n",
    "\n",
    "epochs = 40\n",
    "\n",
    "validation_split=0.1 \n",
    "\n",
    "#n_folds = 5\n",
    "random_seed = 0\n",
    "\n",
    "callbacks = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv(\"HOME\")\n",
    "\n",
    "tb_logdir = os.path.join(home_dir, \"tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# new tensorboard callback at each training\n",
    "# tensorboard_run_id = \"Vocal_magna_2seg_adam_compact_128fbis_128h\"\n",
    "# tb_logdir = \"%s/%s_fold%d %s\" %(tb_logdir, tensorboard_run_id, fold, strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute the following in a terminal:\n",
      "\n",
      "tensorboard --logdir=/home/lidy/tensorboard\n"
     ]
    }
   ],
   "source": [
    "print(\"Execute the following in a terminal:\\n\")\n",
    "print(\"tensorboard --logdir=\" + tb_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TensorBoard in Python\n",
    "tensorboard = TensorBoard(log_dir = tb_logdir)\n",
    "\n",
    "# + add to callbacks\n",
    "callbacks = [tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then open Tensorboard in browser:\n",
    "\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy\n",
      "<keras.optimizers.Adam object at 0x7f6188bbbeb8>\n",
      "['accuracy', <function precision at 0x7f62240a5b70>, <function recall at 0x7f62240a5c80>]\n",
      "Batch size: 32 Epochs: 40\n"
     ]
    }
   ],
   "source": [
    "# Summary of Training options\n",
    "\n",
    "print(loss)\n",
    "print(optimizer)\n",
    "print(metrics)\n",
    "print(\"Batch size:\", batch_size, \"Epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE MODEL\n",
    "\n",
    "model.compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1096 samples, validate on 122 samples\n",
      "Epoch 1/40\n",
      "1096/1096 [==============================] - 316s 289ms/step - loss: 0.4040 - acc: 0.8148 - precision: 0.8474 - recall: 0.9167 - val_loss: 1.0223 - val_acc: 0.6066 - val_precision: 0.9185 - val_recall: 0.4622\n",
      "Epoch 2/40\n",
      "1096/1096 [==============================] - 314s 287ms/step - loss: 0.3292 - acc: 0.8631 - precision: 0.8870 - recall: 0.9366 - val_loss: 1.2387 - val_acc: 0.7377 - val_precision: 0.7288 - val_recall: 1.0000\n",
      "Epoch 3/40\n",
      "1096/1096 [==============================] - 315s 287ms/step - loss: 0.2747 - acc: 0.8905 - precision: 0.9096 - recall: 0.9481 - val_loss: 2.6871 - val_acc: 0.4590 - val_precision: 0.6900 - val_recall: 0.4395\n",
      "Epoch 4/40\n",
      "1096/1096 [==============================] - 314s 287ms/step - loss: 0.3002 - acc: 0.8686 - precision: 0.8970 - recall: 0.9328 - val_loss: 0.3481 - val_acc: 0.8934 - val_precision: 0.8681 - val_recall: 1.0000\n",
      "Epoch 5/40\n",
      " 352/1096 [========>.....................] - ETA: 3:25 - loss: 0.2244 - acc: 0.9148 - precision: 0.9283 - recall: 0.9597"
     ]
    }
   ],
   "source": [
    "# START TRAINING\n",
    "\n",
    "history = model.fit(train_set, train_classes, \n",
    "                     validation_split=validation_split,\n",
    "                     #validation_data=(X_test,y_test), \n",
    "                     epochs=epochs, \n",
    "                     batch_size=batch_size, \n",
    "                     callbacks = callbacks\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Parameters & Techniques\n",
    "\n",
    "Try out more parameters and techniques: (comment/uncomment code blocks below)\n",
    "* Adding ReLU activation\n",
    "* Adding Batch normalization\n",
    "* Adding Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "conv_filters = 16   # number of convolution filters (= CNN depth)\n",
    "filter_size = (3,3)\n",
    "pool_size = (2,2)\n",
    "\n",
    "# Layer 1\n",
    "model.add(Convolution2D(conv_filters, filter_size, padding='valid', input_shape=input_shape))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=pool_size)) \n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Convolution2D(conv_filters, filter_size, padding='valid', input_shape=input_shape))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=pool_size)) \n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "# In order to feed this to a Full(Dense) layer, we need to flatten all data\n",
    "model.add(Flatten()) \n",
    "\n",
    "# Full layer\n",
    "model.add(Dense(256))  \n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "# For binary/2-class problems use ONE sigmoid unit, \n",
    "# for multi-class/multi-label problems use n output units and activation='softmax!'\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIREX 2015 model\n",
    "model = Sequential()\n",
    "\n",
    "conv_filters = 15   # number of convolution filters (= CNN depth)\n",
    "\n",
    "# Layer 1\n",
    "model.add(Convolution2D(conv_filters, (12, 8), padding='valid', input_shape=input_shape))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu')) \n",
    "model.add(Activation('sigmoid')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 1))) \n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "# In order to feed this to a Full(Dense) layer, we need to flatten all data\n",
    "model.add(Flatten()) \n",
    "\n",
    "# Full layer\n",
    "model.add(Dense(200, activation='sigmoid'))  \n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "# For binary/2-class problems use ONE sigmoid unit, \n",
    "# for multi-class/multi-label problems use n output units and activation='softmax!'\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling and training the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7729 - acc: 0.4688\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.7734 - acc: 0.4583\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7648 - acc: 0.5417\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7545 - acc: 0.4583\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6950 - acc: 0.5417\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6950 - acc: 0.5833\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6554 - acc: 0.5833\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6468 - acc: 0.6146\n",
      "Epoch 9/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6807 - acc: 0.6250\n",
      "Epoch 10/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6628 - acc: 0.6042\n",
      "Epoch 11/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7091 - acc: 0.6146\n",
      "Epoch 12/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.6042\n",
      "Epoch 13/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6157 - acc: 0.6667\n",
      "Epoch 14/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6132 - acc: 0.6771\n",
      "Epoch 15/15\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5837 - acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history = model.fit(train_set, train_classes, batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying Accuracy on Test Set\n",
    "\n",
    "test_pred = model.predict_classes(test_set)\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parallel CNNs\n",
    "\n",
    "It has been discovered, that CNNs for music work best, when they have one filter that is detecting frequencies in the vertical axis, and nother filter that is focused on the time axis, i.e. detecting rhythm. Consequently, this is realized in a parallel CNN, where 2 layers are not stacked after each other, but first run independently in parallel with their output being merged later.\n",
    "\n",
    "To create parallel CNNs we need a \"graph-based\" model. In Keras 1.x this is realized via the functional API of the Model() class.\n",
    "We use it to create two CNN layers that run in parallel to each other and are merged subsequently.\n",
    "In the functional API, you pass the name of the previous layer in (brackets) after defining the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input only specifies the input shape\n",
    "input = Input(input_shape)\n",
    "\n",
    "# CNN layers\n",
    "# specify desired number of filters\n",
    "n_filters = 16 \n",
    "# The functional API allows to specify the predecessor in (brackets) after the new Layer function call\n",
    "conv_layer1 = Convolution2D(16, (10, 2))(input)  # a vertical filter\n",
    "conv_layer2 = Convolution2D(25, (2, 10))(input)  # a horizontal filter\n",
    "\n",
    "# possibly add Activation('relu') here\n",
    "\n",
    "# Pooling layers\n",
    "maxpool1 = MaxPooling2D(pool_size=(1,2))(conv_layer1) # horizontal pooling\n",
    "maxpool2 = MaxPooling2D(pool_size=(2,1))(conv_layer2) # vertical pooling\n",
    "\n",
    "# we have to flatten the Pooling output in order to be concatenated\n",
    "flat1 = Flatten()(maxpool1)\n",
    "flat2 = Flatten()(maxpool2)\n",
    "\n",
    "# Merge the 2\n",
    "merged = concatenate([flat1, flat2])\n",
    "\n",
    "full = Dense(256, activation='relu')(merged)\n",
    "output_layer = Dense(1, activation='sigmoid')(full)\n",
    "\n",
    "# finally create the model\n",
    "model = Model(inputs=input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 80, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 31, 79, 16)   336         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 39, 71, 25)   525         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 31, 39, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 19, 71, 25)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 19344)        0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 33725)        0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 53069)        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          13585920    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            257         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,587,038\n",
      "Trainable params: 13,587,038\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function \n",
    "loss = 'binary_crossentropy'  # 'categorical_crossentropy' for multi-class problems\n",
    "\n",
    "# Optimizer = Stochastic Gradient Descent\n",
    "optimizer = 'sgd' \n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.5242 - acc: 0.7188\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2932 - acc: 0.8958\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2043 - acc: 0.9375\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1615 - acc: 0.9688\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1361 - acc: 0.9896\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1095 - acc: 0.9896\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0953 - acc: 0.9896\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 9/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 10/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0641 - acc: 1.0000\n",
      "Epoch 11/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0574 - acc: 1.0000\n",
      "Epoch 12/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0516 - acc: 1.0000\n",
      "Epoch 13/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 14/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 15/15\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0403 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# TRAINING the model\n",
    "epochs = 15\n",
    "history = model.fit(train_set, train_classes, batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set\n",
    "\n",
    "Note: The functional API, i.e. Model() does not have a convenience method `.predict_classes()`. We therefore do 'raw' predictions with `predict()`, which returns values between 0 and 1, and then round to the nearest value (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8116090e-03, 9.9629503e-01, 8.9173570e-02, 1.3832313e-02,\n",
       "       1.5312824e-02, 6.2414613e-02, 9.4741523e-01, 2.8874350e-01,\n",
       "       6.6524655e-02, 7.7041835e-01, 5.9007388e-03, 8.8411587e-01,\n",
       "       7.7622104e-03, 5.5290854e-01, 7.2940448e-03, 9.7821641e-01,\n",
       "       1.9546174e-03, 1.2710236e-01, 2.5445417e-02, 9.2131579e-01,\n",
       "       5.5363268e-01, 7.3306054e-02, 9.8920244e-01, 8.6430952e-02,\n",
       "       8.9812309e-01, 6.6113585e-05, 2.7863439e-03, 9.9372864e-01,\n",
       "       2.8969401e-02, 9.8893112e-01, 7.3728962e-03, 6.7004067e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(test_set)\n",
    "test_pred[0:35,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.round(test_pred)\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
